{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Severity Modelling",
   "id": "9a17587aaa640c26"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This covers the second part of the modelling. The target variable is the loss.",
   "id": "50d7bc46172c2635"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 001: Create the dataset and split dataset",
   "id": "726fe62960d04380"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from model import feature\n",
    "from src.model.dataset import Dataset\n",
    "\n",
    "insurance_initiation_variables_path = \"../data/input/exp/Insurance_Initiation_Variables.csv\"\n",
    "claims_variables_path = \"../data/input/exp/sample_type_claim.csv\"\n",
    "\n",
    "claim_grouping_columns = ['ID', 'Cost_claims_year']\n",
    "claim_aggregation_column = 'Cost_claims_by_type'\n",
    "merging_columns = ['ID', 'Cost_claims_year']\n",
    "\n",
    "dataset = (Dataset(data_path=insurance_initiation_variables_path,\n",
    "                   claims_path=claims_variables_path)\n",
    "           .group_claims(grouping_columns=claim_grouping_columns, aggregation_column=claim_aggregation_column)\n",
    "           .create_dataset(merge_columns=merging_columns)\n",
    "           )\n",
    "trainset, testset = dataset.split_dataset(test_ratio=0.2, to_shuffle=False)"
   ],
   "id": "e201eb1fea07d65a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 002: Engineer relevant features",
   "id": "31989011cb7b791e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from model.feature import main as feature_main\n",
    "\n",
    "features_trainset = feature_main(trainset)\n",
    "features_testset = feature_main(testset)"
   ],
   "id": "1905e2cc56e1b014",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 003: Severity modelling\n",
    "\n",
    "The response variable is the number of claims dubbed `Cost_claims_year` in the dataset. The first step would be to understand the distribution of the response variable"
   ],
   "id": "89e0cef2c1ca92dd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(15, 5))\n",
    "ax0.set_title('Loss Distribution')\n",
    "_ = features_trainset['Cost_claims_year'].hist(bins=40, log=True, ax=ax0)\n",
    "\n",
    "p2_5, p97_5 = np.percentile(features_trainset['Cost_claims_year'], [2.5, 97.5])\n",
    "middle_95 = features_trainset['Cost_claims_year'][(features_trainset['Cost_claims_year'] >= p2_5) &\n",
    "                                                   (features_trainset['Cost_claims_year'] <= p97_5)]\n",
    "ax1.set_title('Middle-95% Loss Distribution (2.5%-97.5%)')\n",
    "_ = middle_95.hist(bins=40, log=False, ax=ax1)\n",
    "\n",
    "print(\n",
    "    \"Average loss distribution: {}\".format(\n",
    "        np.average(features_trainset['Cost_claims_year'])\n",
    "    )\n",
    ")"
   ],
   "id": "c1e950360023f5db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Then we follow the steps have below to fit the model\n",
    "- Define evaluation metrics\n",
    "- Filter for policies with claims severity greater than 0 because gamma distribution support positive values greater than 0\n",
    "- We fit a dummy model and a gamma model and compare both\n",
    "- We review the observed vs predicted for the test set"
   ],
   "id": "47f2d7d85ee44390"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "training_variables = ['Car_age_years', 'Type_risk', 'Area', 'Value_vehicle', 'Distribution_channel',\n",
    "                      'Cylinder_capacity']\n",
    "target = ['Cost_claims_year']"
   ],
   "id": "1b9bf2db0e0e937d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import mean_absolute_error,mean_poisson_deviance,mean_squared_error\n",
    "\n",
    "def model_evaluation_metrics(estimator, df_test, target_variable=target, training_variables=training_variables):\n",
    "    \"\"\"Score an estimator on the test set.\"\"\"\n",
    "    y_pred = estimator.predict(df_test[training_variables])\n",
    "\n",
    "    print(\n",
    "        \"MSE: %.3f\"\n",
    "        % mean_squared_error(\n",
    "            df_test[target], y_pred,\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        \"MAE: %.3f\"\n",
    "        % mean_absolute_error(\n",
    "            df_test[target], y_pred\n",
    "        )\n",
    "    )\n"
   ],
   "id": "e1d39595f4f25981",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_mask = features_trainset['Cost_claims_year']>0\n",
    "updated_features_trainset = features_trainset[train_mask]\n",
    "test_mask = features_testset['Cost_claims_year']>0\n",
    "updated_features_testset = features_testset[test_mask]"
   ],
   "id": "d06f57a9a9334bb1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Model 1 - Baseline Model, Just predicting the mean",
   "id": "12622c0cc458afdd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "dummy = DummyRegressor()\n",
    "dummy_regressor = dummy.fit(updated_features_trainset[training_variables], updated_features_trainset[target])"
   ],
   "id": "3e25d56e86c1b94f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Model 2: Gamma Regressor",
   "id": "b36e6ac934cfdcd6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import GammaRegressor\n",
    "gamma = GammaRegressor(alpha=10, solver=\"newton-cholesky\")\n",
    "gamma_regressor =  gamma.fit(updated_features_trainset[training_variables], updated_features_trainset[target].values.ravel())"
   ],
   "id": "c5e6049905999105",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 004: Severity Modelling Evaluation",
   "id": "4afbd562ba268b50"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for idx, model in enumerate([dummy_regressor, gamma_regressor]):\n",
    "    print(f\"Now evaluating model {str(model)}\")\n",
    "    print(f\"Model metrics : {model_evaluation_metrics(estimator=model, df_test=updated_features_testset, target_variable=target,)}\")\n",
    "    print(\"-------------\")"
   ],
   "id": "9641f74521856283",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_obs_pred(\n",
    "    df,\n",
    "    feature,\n",
    "    observed,\n",
    "    predicted,\n",
    "    y_label=None,\n",
    "    title=None,\n",
    "    ax=None,\n",
    "    fill_legend=False,\n",
    "):\n",
    "    \"\"\"Plot observed and predicted - aggregated per feature level.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        input data\n",
    "    feature: str\n",
    "        a column name of df for the feature to be plotted\n",
    "    weight : str\n",
    "        column name of df with the values of weights or exposure\n",
    "    observed : str\n",
    "        a column name of df with the observed target\n",
    "    predicted : DataFrame\n",
    "        a dataframe, with the same index as df, with the predicted target\n",
    "    fill_legend : bool, default=False\n",
    "        whether to show fill_between legend\n",
    "    \"\"\"\n",
    "    # aggregate observed and predicted variables by feature level\n",
    "    df_ = df.loc[:, [feature]].copy()\n",
    "    df_[\"observed\"] = df[observed] #* df[weight]\n",
    "    df_[\"predicted\"] = predicted #* df[weight]\n",
    "    df_ = (\n",
    "        df_.groupby([feature])[[ \"observed\", \"predicted\"]]\n",
    "        .sum()\n",
    "        .assign(observed=lambda x: x[\"observed\"])\n",
    "        .assign(predicted=lambda x: x[\"predicted\"])\n",
    "    )\n",
    "\n",
    "    ax = df_.loc[:, [\"observed\", \"predicted\"]].plot(style=\".\", ax=ax)\n",
    "    y_max = df_.loc[:, [\"observed\", \"predicted\"]].values.max() * 0.8\n",
    "    p2 = ax.fill_between(\n",
    "        df_.index,\n",
    "        0,\n",
    "        y_max, #* df_[weight] / df_[weight].values.max(),\n",
    "        color=\"g\",\n",
    "        alpha=0.1,\n",
    "    )\n",
    "    if fill_legend:\n",
    "        ax.legend([p2], [\"{} distribution\".format(feature)])\n",
    "    ax.set(\n",
    "        ylabel=y_label if y_label is not None else None,\n",
    "        title=title if title is not None else \"Train: Observed vs Predicted\",\n",
    "    )"
   ],
   "id": "decdbabfa352ee2f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "feature_col = target[0]\n",
    "\n",
    "fig, ax = plt.subplots(ncols=1, figsize=(15, 5))\n",
    "\n",
    "plot_obs_pred(\n",
    "    df=updated_features_testset,\n",
    "    feature=feature_col,\n",
    "    observed=feature_col,\n",
    "    predicted=gamma_regressor.predict(updated_features_testset[training_variables]),\n",
    "    y_label=\"Average claim severity\",\n",
    "    title=\"Predicted vs Observed\",\n",
    "    ax=ax\n",
    ")"
   ],
   "id": "9e4d8078e3e989df",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

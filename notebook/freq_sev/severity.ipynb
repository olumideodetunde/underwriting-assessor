{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Severity Modelling",
   "id": "9a17587aaa640c26"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Overview\n",
    "\n",
    "- This notebook covers the second part of the frequency-severity modelling approach, focusing on predicting claim amounts (severity)\n",
    "- The target variable is `Cost_claims_year` which represents the total claim amount per policy per year\n",
    "- We use a Gamma GLM since claim amounts are strictly positive and right-skewed\n",
    "- Remember that technically `premium = frequency * severity`"
   ],
   "id": "fa71fa938ca06cc3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Setup",
   "id": "1c2e5d5bbadeb438"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import GammaRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error"
   ],
   "id": "aa953af9f2631a4c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Prepare Dataset\n",
    "\n",
    "| Step | Action |\n",
    "|------|--------|\n",
    "| Load | Read insurance and claims data |\n",
    "| Aggregate | Count claims by (ID, year) |\n",
    "| Merge | Left join on (ID, year) |\n",
    "| Fill | NaN â†’ 0 for no claims |\n",
    "| Split | 80/20 train-test split |"
   ],
   "id": "c79edd9133597c52"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.1 Load and merge data",
   "id": "538261d2c0ce99b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "insurance = pd.read_csv('../../data/input/Motor_vehicle_insurance_data.csv', delimiter=\";\")\n",
    "claims =  pd.read_csv('../../data/input/sample_type_claim.csv', delimiter=';')\n",
    "\n",
    "claims_frequency  = (\n",
    "    claims\n",
    "    .groupby(['ID', 'Cost_claims_year'])\n",
    "    .agg({'Cost_claims_by_type': 'count'})\n",
    "    .rename(columns={'Cost_claims_by_type': 'claims_frequency'})\n",
    "    .reset_index()\n",
    ")\n",
    "dataset = (\n",
    "    pd\n",
    "    .merge(\n",
    "        left=insurance,\n",
    "        right=claims_frequency,\n",
    "        how='left',\n",
    "        on=['ID', 'Cost_claims_year']\n",
    "    )\n",
    "    .fillna(value={'claims_frequency':0})\n",
    ")\n",
    "trainset, testset = train_test_split(dataset, test_size=0.2, random_state=42, shuffle=True)"
   ],
   "id": "e201eb1fea07d65a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Engineer Relevant Features",
   "id": "31989011cb7b791e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from src.model.freq_sev.feature import  main as feature_main\n",
    "features_trainset = feature_main(trainset)\n",
    "features_testset = feature_main(testset)"
   ],
   "id": "1905e2cc56e1b014",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Analyse Target Variable [on training data]\n",
    "\n",
    "The response variable is the amount of claims dubbed `Cost_claims_year` in the dataset. Unlike frequency modelling where we predict count of claims, severity modelling predicts the monetary amount.\n",
    "\n",
    "Key considerations for severity modelling:\n",
    "1. Distribution of the response variable (typically right-skewed)\n",
    "2. Only policies with claims (severity > 0) are used for training\n",
    "3. Gamma distribution is appropriate for positive continuous outcomes"
   ],
   "id": "73e90194e8dbe187"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3.1 Distribution of claim severity",
   "id": "fdde5fe4becc54db"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(15, 5))\n",
    "ax0.set_title('Loss Distribution')\n",
    "_ = features_trainset['Cost_claims_year'].hist(bins=40, log=True, ax=ax0)\n",
    "\n",
    "p2_5, p97_5 = np.percentile(features_trainset['Cost_claims_year'], [2.5, 97.5])\n",
    "middle_95 = features_trainset['Cost_claims_year'][(features_trainset['Cost_claims_year'] >= p2_5) &                                         (features_trainset['Cost_claims_year'] <= p97_5)]\n",
    "ax1.set_title('Middle-95% Loss Distribution (2.5%-97.5%)')\n",
    "_ = middle_95.hist(bins=40, log=False, ax=ax1)\n",
    "print(\n",
    "    \"Average loss distribution: {}\".format(\n",
    "        np.average(features_trainset['Cost_claims_year'])\n",
    "    )\n",
    ")"
   ],
   "id": "c1e950360023f5db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- The distribution is heavily right-skewed with a long tail of high-value claims\n",
    "- The middle 95% shows the bulk of claims are concentrated at lower values\n",
    "- This confirms the Gamma distribution is an appropriate choice for modelling"
   ],
   "id": "eb5910ddfab282f8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Model Development\n",
    "\n",
    "| Model | Type | Description |\n",
    "|-------|------|-------------|\n",
    "| Baseline | DummyRegressor | Predict mean |\n",
    "| Gamma | GLM | Severity-specific, handles positive skewed data |"
   ],
   "id": "a9d55bc729bb770c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4.1 Define training variables and evaluation metrics",
   "id": "c56ac8af5c11bf3c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_variables = ['Car_age_years', 'Type_risk', 'Area', 'Value_vehicle', 'Distribution_channel','Cylinder_capacity']\n",
    "target = ['Cost_claims_year']"
   ],
   "id": "1b9bf2db0e0e937d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def model_evaluation_metrics(estimator, df_test, target_variable, training_variables):\n",
    "    y_pred = estimator.predict(df_test[training_variables])\n",
    "    mse = mean_squared_error(df_test[target_variable], y_pred)\n",
    "    mae = mean_absolute_error(df_test[target_variable], y_pred)\n",
    "    print(\n",
    "        \"MSE: %.3f\"\n",
    "        % mse\n",
    "    )\n",
    "    print(\n",
    "        \"MAE: %.3f\"\n",
    "        % mae\n",
    "    )"
   ],
   "id": "e1d39595f4f25981",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 4.2 Filter for policies with claims\n",
    "\n",
    "Because we are fitting a Gamma regressor, we filter out policies where no claims have been made. The Gamma distribution only supports strictly positive values (y > 0)."
   ],
   "id": "70d7ebb297a09500"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_mask = features_trainset['Cost_claims_year']>0\n",
    "updated_features_trainset = features_trainset[train_mask]\n",
    "test_mask = features_testset['Cost_claims_year']>0\n",
    "updated_features_testset = features_testset[test_mask]"
   ],
   "id": "d06f57a9a9334bb1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4.3 Model 1: Baseline (Mean Prediction)",
   "id": "12622c0cc458afdd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "dummy = DummyRegressor(strategy=\"mean\")\n",
    "dummy_regressor = dummy.fit(updated_features_trainset[train_variables], updated_features_trainset[target])\n",
    "print(\"Constant mean severity evaluation:\")\n",
    "model_evaluation_metrics(estimator=dummy_regressor, df_test=updated_features_testset, target_variable=target, training_variables=train_variables)"
   ],
   "id": "3e25d56e86c1b94f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4.4 Model 2: Gamma Regressor",
   "id": "b36e6ac934cfdcd6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "gamma = GammaRegressor(alpha=10,\n",
    "                       solver=\"newton-cholesky\",\n",
    "                       max_iter=10000, )\n",
    "gamma_regressor =  gamma.fit(updated_features_trainset[train_variables], updated_features_trainset[target].values.ravel())\n",
    "print(\"Gamma regression evaluation:\")\n",
    "model_evaluation_metrics(estimator=gamma_regressor, df_test=updated_features_testset, target_variable=target, training_variables=train_variables)"
   ],
   "id": "ded53485013050bb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. Model Evaluation\n",
    "\n",
    "| Check | Purpose |\n",
    "|-------|---------|\n",
    "| Metrics comparison | Compare MSE/MAE across models |\n",
    "| Observed vs Predicted | Visual calibration check |"
   ],
   "id": "4afbd562ba268b50"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5.1 Model comparison",
   "id": "1437c3bf01eb6ecb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for idx, model in enumerate([dummy_regressor, gamma_regressor]):\n",
    "    print(f\"Now evaluating model {model.__class__.__name__}\")\n",
    "    model_evaluation_metrics(estimator=model, df_test=updated_features_testset, target_variable=target, training_variables=train_variables)\n",
    "    print(\"-------------\")"
   ],
   "id": "9641f74521856283",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5.2 Observed vs Predicted visualization",
   "id": "8770af43f5d35d7e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_obs_pred(\n",
    "    df,\n",
    "    feature,\n",
    "    observed,\n",
    "    predicted,\n",
    "    y_label=None,\n",
    "    title=None,\n",
    "    ax=None,\n",
    "    fill_legend=False,\n",
    "):\n",
    "    # aggregate observed and predicted variables by feature level\n",
    "    df_ = df.loc[:, [feature]].copy()\n",
    "    df_[\"observed\"] = df[observed] #* df[weight]\n",
    "    df_[\"predicted\"] = predicted #* df[weight]\n",
    "    df_ = (\n",
    "        df_.groupby([feature])[[ \"observed\", \"predicted\"]]\n",
    "        .sum()\n",
    "        .assign(observed=lambda x: x[\"observed\"])\n",
    "        .assign(predicted=lambda x: x[\"predicted\"])\n",
    "    )\n",
    "    ax = df_.loc[:, [\"observed\", \"predicted\"]].plot(style=\".\", ax=ax)\n",
    "    y_max = df_.loc[:, [\"observed\", \"predicted\"]].values.max() * 0.8\n",
    "    p2 = ax.fill_between(\n",
    "        df_.index,\n",
    "        0,\n",
    "        y_max, #* df_[weight] / df_[weight].values.max(),\n",
    "        color=\"g\",\n",
    "        alpha=0.1,\n",
    "    )\n",
    "    if fill_legend:\n",
    "        ax.legend([p2], [\"{} distribution\".format(feature)])\n",
    "    ax.set(\n",
    "        ylabel=y_label if y_label is not None else None,\n",
    "        title=title if title is not None else \"Train: Observed vs Predicted\",\n",
    "    )"
   ],
   "id": "decdbabfa352ee2f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "feature_col = target[0]\n",
    "fig, ax = plt.subplots(ncols=1, figsize=(15, 5))\n",
    "plot_obs_pred(\n",
    "    df=updated_features_testset,\n",
    "    feature=feature_col,\n",
    "    observed=feature_col,\n",
    "    predicted=gamma_regressor.predict(updated_features_testset[train_variables]),\n",
    "    y_label=\"Average claim severity\",\n",
    "    title=\"Predicted vs Observed\",\n",
    "    ax=ax\n",
    ")"
   ],
   "id": "1a6276ab8db8ed0d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#TODO: Add more severity models (e.g., GBM with gamma loss), introduce mlflow\n",
   "id": "d3726d90349f45ec"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

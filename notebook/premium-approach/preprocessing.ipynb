{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b086f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin    \n",
    "from sklearn.impute import SimpleImputer\n",
    "from feature_eng import feature_engineering\n",
    "from datasets import insurance_new as dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import category_encoders as ce\n",
    "\n",
    "# load the dataset\n",
    "feature, target = feature_engineering(dataset)\n",
    "\n",
    "# split the dataset into training and testing sets\n",
    "train_x, test_x, train_y, test_y = train_test_split(\n",
    "    feature, target, test_size=0.1, random_state=42, shuffle=False\n",
    ")\n",
    "\n",
    "# Preprocessor class for data preprocessing\n",
    "class Preprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(\n",
    "        self,\n",
    "        target_smoothing=0.3,\n",
    "        min_samples_leaf=20,\n",
    "        handle_unknown=\"value\"\n",
    "    ):\n",
    "        # Store parameters EXACTLY as passed\n",
    "        self.target_smoothing = target_smoothing\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.handle_unknown = handle_unknown\n",
    "\n",
    "        # Define components\n",
    "        self.num_imputer = SimpleImputer(strategy=\"mean\")\n",
    "        self.cat_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "        self.encoder = ce.TargetEncoder(\n",
    "            smoothing=self.target_smoothing,\n",
    "            min_samples_leaf=self.min_samples_leaf,\n",
    "            handle_unknown=self.handle_unknown\n",
    "        )\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if y is None:\n",
    "            raise ValueError(\"Target y must be provided for target encoding.\")\n",
    "\n",
    "        # Lock schema\n",
    "        self.num_cols_ = (\n",
    "            X.select_dtypes(include=[\"int64\", \"float64\"])\n",
    "            .columns\n",
    "            .tolist()\n",
    "        )\n",
    "        self.cat_cols_ = (\n",
    "            X.select_dtypes(include=[\"object\", \"category\"])\n",
    "            .columns\n",
    "            .tolist()\n",
    "        )\n",
    "\n",
    "        self.feature_names_ = self.num_cols_ + self.cat_cols_\n",
    "\n",
    "        # Fit imputers\n",
    "        self.num_imputer.fit(X[self.num_cols_])\n",
    "        self.cat_imputer.fit(X[self.cat_cols_])\n",
    "\n",
    "        # Fit target encoder on imputed categorical data\n",
    "        X_cat_imputed = pd.DataFrame(\n",
    "            self.cat_imputer.transform(X[self.cat_cols_]),\n",
    "            columns=self.cat_cols_,\n",
    "            index=X.index\n",
    "        )\n",
    "\n",
    "        self.encoder.fit(X_cat_imputed, y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Schema validation\n",
    "        missing = set(self.feature_names_) - set(X.columns)\n",
    "        if missing:\n",
    "            raise ValueError(f\"Missing columns at transform time: {missing}\")\n",
    "\n",
    "        # Enforce column order and drop extras\n",
    "        X = X[self.feature_names_]\n",
    "\n",
    "        # Impute\n",
    "        X_num = pd.DataFrame(\n",
    "            self.num_imputer.transform(X[self.num_cols_]),\n",
    "            columns=self.num_cols_,\n",
    "            index=X.index\n",
    "        )\n",
    "\n",
    "        X_cat = pd.DataFrame(\n",
    "            self.cat_imputer.transform(X[self.cat_cols_]),\n",
    "            columns=self.cat_cols_,\n",
    "            index=X.index\n",
    "        )\n",
    "\n",
    "        # Encode\n",
    "        X_cat_enc = pd.DataFrame(\n",
    "            self.encoder.transform(X_cat),\n",
    "            columns=self.cat_cols_,\n",
    "            index=X.index\n",
    "        )\n",
    "\n",
    "        return pd.concat([X_num, X_cat_enc], axis=1)\n",
    "    \n",
    "    # Get feature names after transformation\n",
    "    def get_feature_names_out(self):\n",
    "        return self.num_cols_ + self.cat_cols_\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Preprocessing module loaded successfully.\")\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

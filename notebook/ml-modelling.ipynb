{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Modelling"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's attempt to build a frequency vs severity model using both GLM and GBM. Remember that technically `premium = frequency * severity`\n",
    "- Bonus: see if along the way we can use the variable importance to identify key rating factors for both frequency and severity that can be used for risk classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 001: Create the dataset and split dataset"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T19:33:17.855480Z",
     "start_time": "2025-09-08T19:33:17.569116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.dataset import Dataset\n",
    "\n",
    "\n",
    "insurance_initiation_variables_path = \"../data/input/exp/Insurance_Initiation_Variables.csv\"\n",
    "claims_variables_path = \"../data/input/exp/sample_type_claim.csv\"\n",
    "\n",
    "claim_grouping_columns = ['ID', 'Cost_claims_year']\n",
    "claim_aggregation_column = 'Cost_claims_by_type'\n",
    "merging_columns = ['ID', 'Cost_claims_year']\n",
    "\n",
    "dataset =  (Dataset(data_path=insurance_initiation_variables_path,\n",
    "                              claims_path=claims_variables_path)\n",
    "                      .group_claims(grouping_columns=claim_grouping_columns,aggregation_column=claim_aggregation_column)\n",
    "                      .create_dataset(merge_columns=merging_columns)\n",
    "                     )\n",
    "trainset, testset = dataset.split_dataset(test_ratio=0.2, to_shuffle=False)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T19:34:51.936525Z",
     "start_time": "2025-09-08T19:34:51.933596Z"
    }
   },
   "cell_type": "markdown",
   "source": "## 002: Engineer relevant features"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T19:40:51.753447Z",
     "start_time": "2025-09-08T19:40:45.460663Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.feature import  main as feature_main\n",
    "\n",
    "features_trainset = feature_main(trainset)\n",
    "features_testset = feature_main(testset)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 003: Frequency modelling - Poisson regression\n",
    "\n",
    "The response variable is the number of claims dubbed `claims_frequency` in the dataset. Let's check a few assumptions before we fit a Poisson regression model:\n",
    "\n",
    "1. Distribution of the response variable\n",
    "2. Equidispersion: the mean and variance of the response variable should be roughly equal"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "cols = ['claims_frequency']\n",
    "bins = 10\n",
    "fig, axes = plt.subplots(1, len(cols), figsize=(18, 3))\n",
    "if len(cols) == 1:\n",
    "    axes = [axes]\n",
    "for i, col in enumerate(cols):\n",
    "    sns.histplot(data=features_trainset, x=col, bins=bins, kde=False, ax=axes[i])\n",
    "    axes[i].set_title(f\"Distribution of {col}\")\n",
    "plt.tight_layout()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mean_claims_frequency = features_trainset['claims_frequency'].mean()\n",
    "var_claims_frequency = features_trainset['claims_frequency'].var()\n",
    "print(f\"Mean of claims_frequency: {mean_claims_frequency}\")\n",
    "print(f\"Variance of claims_frequency: {var_claims_frequency}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- From the both the histogram and the mean-variance comparison, we can see that the claims frequency is unimodal and rightly skewed, the mean and variance are not roughly equal (variance is smaller than the mean). This indicates that the data is underdispersed. So lets try to fit a poisson regression model and see how it performs."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T20:20:53.421635Z",
     "start_time": "2025-09-09T20:20:53.378634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Fit the poisson regression model using statsmodel formula api\n",
    "from statsmodels.formula.api import poisson\n",
    "training_variables = ['Driver_age_years', 'Driver_experience_years', 'Car_age_years', 'power_to_weight', 'Type_risk', 'claims_frequency']\n",
    "poisson_model = poisson('claims_frequency ~ Driver_age_years + Driver_experience_years + Car_age_years + power_to_weight + Type_risk', data=features_trainset)\n",
    "result = poisson_model.fit()\n",
    "print(result.summary())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 1.264404\n",
      "         Iterations 4\n",
      "                          Poisson Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:       claims_frequency   No. Observations:                 4112\n",
      "Model:                        Poisson   Df Residuals:                     4106\n",
      "Method:                           MLE   Df Model:                            5\n",
      "Date:                Tue, 09 Sep 2025   Pseudo R-squ.:               0.0001380\n",
      "Time:                        21:20:53   Log-Likelihood:                -5199.2\n",
      "converged:                       True   LL-Null:                       -5199.9\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.9205\n",
      "===========================================================================================\n",
      "                              coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "Intercept                   0.2531      0.117      2.171      0.030       0.025       0.482\n",
      "Driver_age_years           -0.0005      0.002     -0.210      0.834      -0.005       0.004\n",
      "Driver_experience_years     0.0004      0.002      0.170      0.865      -0.004       0.005\n",
      "Car_age_years               0.0024      0.002      1.021      0.307      -0.002       0.007\n",
      "power_to_weight            -0.0042      0.263     -0.016      0.987      -0.519       0.511\n",
      "Type_risk                   0.0178      0.027      0.659      0.510      -0.035       0.071\n",
      "===========================================================================================\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T20:26:53.843818Z",
     "start_time": "2025-09-09T20:25:37.574885Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Fit the poisson model using discrete Generalized Poisson model from statsmodels\n",
    "from statsmodels.discrete.discrete_model import GeneralizedPoisson\n",
    "generalised_poisson_model = GeneralizedPoisson(endog=features_trainset['claims_frequency'], exog=features_trainset[['Driver_age_years', 'Driver_experience_years', 'Car_age_years', 'power_to_weight', 'Type_risk']], p=2).fit(method='nm')\n",
    "print(generalised_poisson_model.summary())"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/olumide/Library/CloudStorage/OneDrive-Personal/Documents/Research/Project 1/underwriting assessor/.venv/lib/python3.13/site-packages/statsmodels/base/optimizer.py:737: RuntimeWarning: Maximum number of iterations has been exceeded.\n",
      "  retvals = optimize.fmin(f, start_params, args=fargs, xtol=xtol,\n",
      "/Users/olumide/Library/CloudStorage/OneDrive-Personal/Documents/Research/Project 1/underwriting assessor/.venv/lib/python3.13/site-packages/statsmodels/base/model.py:595: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  warnings.warn('Inverting hessian failed, no bse or cov_params '\n",
      "/Users/olumide/Library/CloudStorage/OneDrive-Personal/Documents/Research/Project 1/underwriting assessor/.venv/lib/python3.13/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    GeneralizedPoisson Regression Results                     \n",
      "==============================================================================\n",
      "Dep. Variable:       claims_frequency   No. Observations:                84444\n",
      "Model:             GeneralizedPoisson   Df Residuals:                    84439\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Tue, 09 Sep 2025   Pseudo R-squ.:                     nan\n",
      "Time:                        21:26:53   Log-Likelihood:                    nan\n",
      "converged:                      False   LL-Null:                           nan\n",
      "Covariance Type:            nonrobust   LLR p-value:                       nan\n",
      "===========================================================================================\n",
      "                              coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "Driver_age_years               nan        nan        nan        nan         nan         nan\n",
      "Driver_experience_years        nan        nan        nan        nan         nan         nan\n",
      "Car_age_years                  nan        nan        nan        nan         nan         nan\n",
      "power_to_weight                nan        nan        nan        nan         nan         nan\n",
      "Type_risk                      nan        nan        nan        nan         nan         nan\n",
      "alpha                      -0.1000        nan        nan        nan         nan         nan\n",
      "===========================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/olumide/Library/CloudStorage/OneDrive-Personal/Documents/Research/Project 1/underwriting assessor/.venv/lib/python3.13/site-packages/statsmodels/base/model.py:595: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  warnings.warn('Inverting hessian failed, no bse or cov_params '\n",
      "/Users/olumide/Library/CloudStorage/OneDrive-Personal/Documents/Research/Project 1/underwriting assessor/.venv/lib/python3.13/site-packages/statsmodels/base/model.py:595: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  warnings.warn('Inverting hessian failed, no bse or cov_params '\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "#TODO: interpret the model results and look into evaluation metrics"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
